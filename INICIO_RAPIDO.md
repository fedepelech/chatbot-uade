# üöÄ Inicio R√°pido - UadeBot

Comandos para levantar y testear la aplicaci√≥n completa desde cero.

---

## üìã Pre-requisitos

Verificar que Docker est√© instalado y corriendo:

```bash
docker --version
docker-compose --version
```

---

## üéØ Levantar la Aplicaci√≥n Completa

### Paso 1: Navegar al directorio del proyecto

```bash
cd /home/federico/Documentos/Facu/chatbot-uade
```

### Paso 2: Levantar todos los contenedores

```bash
docker-compose up -d --build
```

**Qu√© hace este comando:**
- `up`: Inicia los servicios
- `-d`: Modo detached (en segundo plano)
- `--build`: Construye las im√°genes antes de iniciar

**Salida esperada:**
```
[+] Building 45.2s (24/24) FINISHED
[+] Running 4/4
 ‚úî Network chatbot-uade_default         Created
 ‚úî Container chatbot-uade-ollama-1      Started
 ‚úî Container chatbot-uade-backend-1     Started
 ‚úî Container chatbot-uade-frontend-1    Started
```

### Paso 3: Verificar que los contenedores est√©n corriendo

```bash
docker-compose ps
```

**Salida esperada:**
```
NAME                        STATUS              PORTS
chatbot-uade-frontend-1     Up 30 seconds       0.0.0.0:3000->3000/tcp
chatbot-uade-backend-1      Up 30 seconds       0.0.0.0:4000->4000/tcp
chatbot-uade-ollama-1       Up 30 seconds       0.0.0.0:11434->11434/tcp
```

### Paso 4: Ver logs para confirmar que todo inici√≥ correctamente

```bash
# Ver logs de todos los servicios
docker-compose logs

# O ver logs en tiempo real
docker-compose logs -f
```

**Presiona Ctrl+C para salir de los logs**

### Paso 5: Descargar el modelo de Ollama (PRIMERA VEZ SOLAMENTE)

**Abrir una nueva terminal** y ejecutar:

```bash
docker exec -it chatbot-uade-ollama-1 ollama pull gemma3:1b
```

**Tiempo estimado:** 2-5 minutos (depende de tu conexi√≥n)

**Salida esperada:**
```
pulling manifest
pulling 8eeb52dfb3bb... 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.5 GB
pulling 097a36493f71... 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  8.4 KB
pulling 109037bec39c... 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  136 B
pulling 22f7f7540a20... 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   59 B
pulling 887433b89a90... 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  483 B
verifying sha256 digest
writing manifest
success
```

### Paso 6: Verificar que el modelo se descarg√≥

```bash
docker exec -it chatbot-uade-ollama-1 ollama list
```

**Salida esperada:**
```
NAME            ID              SIZE      MODIFIED
gemma3:1b       abc123def456    1.5 GB    2 minutes ago
```

---

## ‚úÖ Testing de la Aplicaci√≥n

### Test 1: Verificar Frontend

```bash
# Abrir en el navegador
xdg-open http://localhost:3000
# O en Mac: open http://localhost:3000
# O en Windows: start http://localhost:3000
```

**O manualmente:** Abre tu navegador y ve a http://localhost:3000

**Deber√≠as ver:**
- Interfaz del chatbot UadeBot
- Header con "UadeBot"
- Input para escribir mensajes

### Test 2: Verificar Backend (Health Check)

```bash
curl http://localhost:4000/health
```

**Salida esperada:**
```json
{"status":"ok"}
```

### Test 3: Verificar Ollama

```bash
curl http://localhost:11434/api/tags
```

**Salida esperada:**
```json
{"models":[{"name":"gemma3:1b","modified_at":"...","size":1500000000}]}
```

### Test 4: Probar el chatbot end-to-end

1. **Configurar legajo en el navegador:**
   - Abre http://localhost:3000
   - Abre la consola del navegador (F12)
   - Ejecuta:
   ```javascript
   localStorage.setItem('legajo', '123456');
   ```
   - Recarga la p√°gina (F5)

2. **Enviar un mensaje de prueba:**
   - Escribe en el chat: "¬øCu√°nto debo de la cuota?"
   - Presiona Enter o click en "Enviar"

3. **Verificar respuesta:**
   - Deber√≠as ver el indicador "escribiendo..."
   - Luego una respuesta del bot con informaci√≥n de la cuenta

### Test 5: Ver logs en tiempo real durante el test

**En otra terminal:**

```bash
# Ver logs del backend
docker-compose logs -f backend
```

**Deber√≠as ver:**
```
[MCP] Procesando prompt del usuario: "¬øCu√°nto debo de la cuota?"
[SELECT_TOOL] Usando 9 tools disponibles para selecci√≥n
[LLM] Tool selection response: {"tool":"get_cuenta_corriente","parameters":{"legajo":"123456"}}
[EXECUTE_TOOL] Ejecutando tool: get_cuenta_corriente
[EXECUTE_TOOL] Tool ejecutada exitosamente: get_cuenta_corriente
```

---

## üîç Verificaci√≥n Completa

### Checklist de Testing:

```bash
# 1. Contenedores corriendo
docker-compose ps
# ‚úì Todos deben estar "Up"

# 2. Frontend accesible
curl -I http://localhost:3000
# ‚úì Debe retornar HTTP 200

# 3. Backend accesible
curl http://localhost:4000/health
# ‚úì Debe retornar {"status":"ok"}

# 4. Ollama accesible
curl http://localhost:11434/api/tags
# ‚úì Debe listar el modelo gemma3:1b

# 5. Logs sin errores cr√≠ticos
docker-compose logs | grep -i error
# ‚úì No debe haber errores cr√≠ticos
```

---

## üìä Monitoreo en Tiempo Real

### Ver uso de recursos

```bash
docker stats
```

**Salida esperada:**
```
CONTAINER ID   NAME                      CPU %   MEM USAGE / LIMIT
abc123         chatbot-uade-frontend-1   0.5%    50MiB / 8GiB
def456         chatbot-uade-backend-1    2.0%    200MiB / 8GiB
ghi789         chatbot-uade-ollama-1     15.0%   2GiB / 8GiB
```

### Ver logs de un servicio espec√≠fico

```bash
# Frontend
docker-compose logs -f frontend

# Backend
docker-compose logs -f backend

# Ollama
docker-compose logs -f ollama
```

---

## üõë Detener la Aplicaci√≥n

### Detener todos los contenedores

```bash
docker-compose down
```

**Salida esperada:**
```
[+] Running 4/4
 ‚úî Container chatbot-uade-frontend-1   Removed
 ‚úî Container chatbot-uade-backend-1    Removed
 ‚úî Container chatbot-uade-ollama-1     Removed
 ‚úî Network chatbot-uade_default        Removed
```

**Nota:** Esto NO elimina el modelo descargado (se guarda en un volumen)

### Detener y eliminar TODO (incluyendo vol√∫menes)

```bash
docker-compose down -v
```

**‚ö†Ô∏è CUIDADO:** Esto eliminar√° el modelo de Ollama y tendr√°s que descargarlo de nuevo.

---

## üîÑ Reiniciar la Aplicaci√≥n

### Si ya descargaste el modelo antes:

```bash
# Simplemente levantar los contenedores
docker-compose up -d
```

**No necesitas `--build` si no cambiaste c√≥digo**

### Ver logs al iniciar

```bash
docker-compose up
```

**Sin `-d` ver√°s los logs en tiempo real**
**Presiona Ctrl+C para detener**

---

## üêõ Troubleshooting

### Problema: Puerto ya en uso

```bash
# Ver qu√© proceso usa el puerto 3000
sudo lsof -i :3000

# O cambiar el puerto en docker-compose.yml
# "3001:3000" en lugar de "3000:3000"
```

### Problema: Contenedor no inicia

```bash
# Ver logs del contenedor problem√°tico
docker-compose logs backend

# Reiniciar el contenedor
docker-compose restart backend

# Reconstruir si es necesario
docker-compose up -d --build backend
```

### Problema: Modelo no descarga

```bash
# Verificar espacio en disco
df -h

# Verificar logs de Ollama
docker-compose logs ollama

# Intentar descargar manualmente
docker exec -it chatbot-uade-ollama-1 ollama pull gemma3:1b
```

### Problema: Frontend muestra error de conexi√≥n

```bash
# Verificar que el backend est√© corriendo
curl http://localhost:4000/health

# Verificar logs del backend
docker-compose logs -f backend

# Reiniciar backend
docker-compose restart backend
```

---

## üìù Resumen de Comandos Esenciales

```bash
# LEVANTAR TODO
docker-compose up -d --build

# DESCARGAR MODELO (primera vez)
docker exec -it chatbot-uade-ollama-1 ollama pull gemma3:1b

# VER ESTADO
docker-compose ps

# VER LOGS
docker-compose logs -f

# DETENER TODO
docker-compose down

# REINICIAR
docker-compose restart

# LIMPIAR TODO
docker-compose down -v
```

---

## üéØ Workflow Completo (Copy-Paste)

```bash
# 1. Ir al directorio
cd /home/federico/Documentos/Facu/chatbot-uade

# 2. Levantar contenedores
docker-compose up -d --build

# 3. Esperar 30 segundos
sleep 30

# 4. Descargar modelo (primera vez)
docker exec -it chatbot-uade-ollama-1 ollama pull gemma3:1b

# 5. Verificar que todo est√© OK
docker-compose ps
curl http://localhost:4000/health
curl http://localhost:11434/api/tags

# 6. Abrir navegador
echo "Abre http://localhost:3000 en tu navegador"

# 7. Ver logs en tiempo real
docker-compose logs -f
```

---

**¬°Listo! Tu aplicaci√≥n UadeBot est√° corriendo y lista para probar.** üéâ

**URLs importantes:**
- Frontend: http://localhost:3000
- Backend: http://localhost:4000
- Ollama: http://localhost:11434
